{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYT85KBKDaFo"
      },
      "source": [
        "# Module 6: Automating Scientific Discovery\n",
        "---\n",
        "\n",
        "Welcome to the practical session of [Data-Driven Life Sciences course module 6](https://ddls.aicell.io/course/ddls-2024/module-6/), created by Gabriel Reder. And, Professor Wei Ouyang, teaching assistants Songtao Cheng, and Nils Mechtel made some modifications.\n",
        "\n",
        "## Introduction\n",
        "This notebook will guide exploration of automating the experimental side of scientific discovery in the laboratory. The aim is to encourage thinking about everyday manual tasks in experiments that can be aided through the use of LLM models and AI systems boosting the power of laboratory robotics.\n",
        "\n",
        "**Authors**: Gabriel Reder (gk@reder.io)\n",
        "\n",
        "# TODO: more introduction\n",
        "\n",
        "We will use concepts that were discussed in the lecture, such as lab automation and hypha to connect your mcp tool to Gemini."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcZDjd5eEDJ0"
      },
      "source": [
        "### Important Note for This Lab Notebook:\n",
        "\n",
        "- **🌞 Tasks Introduction:** Sections marked with a 🌞 symbol introduce an exercise or question. Please read these sections carefully to understand the concepts and tasks involved.\n",
        "\n",
        "- **⭐ Your Answer Here:** Cells marked with a ⭐ symbol indicate where you need to write your answer. Please provide your code or answer there."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Setup\n",
        "\n",
        "### Save the notebook to your Module 6 folder in Google Drive\n",
        "\n",
        "Before you start, copy this notebook to your Google Drive:\n",
        "\n",
        "`File` -> `Save a copy in Drive`\n",
        "\n",
        "(You can close the other tab with the original notebook.)\n",
        "\n",
        "Next, move the copied notebook to your Module 6 folder in Google Drive:\n",
        "\n",
        "`File` -> `Move` -> Go up to `My Drive` -> Select your `DDLS-Course` folder -> Create a new folder named `Module6` -> `Select folder`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Runtime\n",
        "\n",
        "You can run this notebook with a **CPU** runtime. A GPU runtime is not required because of the small model size."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Mount Google Drive Folder\n",
        "\n",
        "Mounting your Google Drive folder allows your Colab notebook to access files stored in your Google Drive. This is useful for loading datasets, saving results, or accessing other files you need for your work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you copied and saved the notebook correctly, you should now see this notebook in your Google Drive under `/content/drive/MyDrive/DDLS-Course/Module6/`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!ls -lh /content/drive/MyDrive/DDLS-Course/Module6/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWwT2upGELXN"
      },
      "source": [
        "## Installing dependencies\n",
        "We'll need the `opentrons` python package to simulate running protocols, so we'll install that now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRk99LolBWGk"
      },
      "outputs": [],
      "source": [
        "!pip install opentrons mcp pydantic hypha_rpc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Working with Gemini CLI in Google Colab\n",
        "\n",
        "Open the terminal in Google Colab and run the following commands to install Gemini CLI:\n",
        "\n",
        "```bash\n",
        "curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.40.3/install.sh | bash\n",
        "source /root/.bashrc\n",
        "nvm install 21\n",
        "nvm use 21\n",
        "npm install -g @google/gemini-cli\n",
        "```\n",
        "\n",
        "**Start Gemini CLI**\n",
        "\n",
        "To start a Gemini chat session, first change your working directory to your Module 5 folder in Google Drive:\n",
        "\n",
        "```bash\n",
        "cd /content/drive/MyDrive/DDLS-Course/Module6/\n",
        "```\n",
        "\n",
        "and then run the `gemini` command:\n",
        "\n",
        "```bash\n",
        "gemini\n",
        "```\n",
        "\n",
        "**Save Your Gemini Chat History**\n",
        "\n",
        "Remember to regularly save your Gemini chat history to avoid losing records of your work. In the Gemini CLI, run:\n",
        "```\n",
        "/chat save computer-lab-6\n",
        "```\n",
        "\n",
        "**Copy the Checkpoint File**\n",
        "\n",
        "Ask Gemini to copy the checkpoint file from the temporary Gemini directory to your Google Drive folder while you are still in the Gemini CLI session:\n",
        "```\n",
        "Run this command: `cp /root/.gemini/tmp/*/checkpoint-computer-lab-6.json .`\n",
        "```\n",
        "\n",
        "You can do so after every small or large step of your work. This will prevent the loss of your chat history if runtime in Google Colab disconnects and gets reset.\n",
        "\n",
        "If you have already closed the Gemini CLI session, run this command to copy the checkpoint file to your Google Drive folder:\n",
        "```bash\n",
        "cd /content/drive/MyDrive/DDLS-Course/Module6/\n",
        "cp /root/.gemini/tmp/*/checkpoint-computer-lab-6.json .\n",
        "```\n",
        "\n",
        "**Load Your Gemini Chat History**\n",
        "\n",
        "To load your previously saved Gemini chat history, run the following command in the Gemini CLI:\n",
        "```\n",
        "/chat load computer-lab-6\n",
        "```\n",
        "\n",
        "**General tips when working on large data files**\n",
        "\n",
        "Don’t let Gemini read the entire files. Instead use preview commands like `head` or `tail`. Also avoid printing details and always keep the outputs concise.\n",
        "\n",
        "It can help to add instructions like this to your GEMINI.md file.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJKs2mXeFKex"
      },
      "source": [
        "# Creating robotic lab protocols\n",
        "\n",
        "## Opentron liquid handlers\n",
        "For this exercise, we'll suppose you are running a lab equipped with an Opentron flex liquid handling robot:\n",
        "\n",
        "<figure>\n",
        "<center>\n",
        "<img src=\"https://cdn11.bigcommerce.com/s-zmwgbev7rb/products/255/images/814/Flex-6__84033.1719413544.386.513.png?c=1\" width=\"350\">\n",
        "</figure>\n",
        "\n",
        "If you'd like to see the robot in action, take a look at this marketing [video](https://www.youtube.com/watch?v=d6ln-0LeT8A)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWYWhrskGqDq"
      },
      "source": [
        "## A sample Opentron protocol\n",
        "\n",
        "One thing that's nice about Opentrons is that they have a Python API, meaning we can write scripts to execute protocols directly on the robot. Take a look at the sample protocol below. Can you tell what's going on?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHcwwrJhCD3p"
      },
      "outputs": [],
      "source": [
        "from opentrons.simulate import get_protocol_api\n",
        "\n",
        "\n",
        "def sample_protocol():\n",
        "    # Create a ProtocolContext for the Flex robot\n",
        "    protocol = get_protocol_api(\n",
        "        version=\"2.19\", robot_type=\"Flex\"  # API version 2.19  # Flex robot\n",
        "    )\n",
        "    print(\"Protocol API version:\", protocol.api_version)\n",
        "\n",
        "    # Load the labware (plate, tiprack, trash)\n",
        "    plate = protocol.load_labware(\n",
        "        load_name=\"corning_96_wellplate_360ul_flat\", location=\"D1\"\n",
        "    )\n",
        "    print(\"Loaded labware:\", plate)\n",
        "\n",
        "    tiprack_1 = protocol.load_labware(\n",
        "        load_name=\"opentrons_flex_96_tiprack_200ul\", location=\"D2\"\n",
        "    )\n",
        "    print(\"Loaded labware:\", tiprack_1)\n",
        "\n",
        "    trash = protocol.load_trash_bin(location=\"D3\")\n",
        "    print(\"Loaded labware:\", trash)\n",
        "\n",
        "    # Load the instrument (pipette)\n",
        "    pipette = protocol.load_instrument(\n",
        "        instrument_name=\"flex_1channel_1000\",\n",
        "        mount=\"left\",\n",
        "        tip_racks=[tiprack_1],  # specify the tiprack(s) to pull tips from\n",
        "    )\n",
        "    print(\"Loaded instrument:\", pipette)\n",
        "\n",
        "    # Define the protocol steps\n",
        "    print(\"Starting protocol...\")\n",
        "\n",
        "    pipette.pick_up_tip(location=tiprack_1)\n",
        "    print(\"Picked up tip from A1\")\n",
        "\n",
        "    pipette.aspirate(volume=100, location=plate[\"A1\"])\n",
        "    print(\"Aspirated 100uL from A1\")\n",
        "\n",
        "    pipette.dispense(volume=100, location=plate[\"B1\"])\n",
        "    print(\"Dispensed 100uL to B1\")\n",
        "\n",
        "    pipette.drop_tip(location=trash)\n",
        "    print(\"Dropped tip to trash\")\n",
        "\n",
        "    print(\"Protocol complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Simulating protocols\n",
        "\n",
        "The opentron API allows us to simulate protocols, even if we don't have a robot. Let's try this out on our sample protocol. Make sure you have executed the cell above containing the sample protocol.\n",
        "\n",
        "Now, execute the cell below to simulate the sample protocol and see what it does."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/nilsm/.opentrons/robot_settings.json not found. Loading defaults\n",
            "Belt calibration not found.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Protocol API version: 2.19\n",
            "Loaded labware: Corning 96 Well Plate 360 µL Flat\n",
            "Loaded labware: Opentrons Flex 96 Tip Rack 200 µL\n",
            "Loaded labware: <opentrons.protocol_api.disposal_locations.TrashBin object at 0x137aac310>\n",
            "Loaded instrument: Flex 1-Channel 1000 µL on left mount\n",
            "Starting protocol...\n",
            "Picked up tip from A1\n",
            "Aspirated 100uL from A1\n",
            "Dispensed 100uL to B1\n",
            "Dropped tip to trash\n",
            "Protocol complete.\n"
          ]
        }
      ],
      "source": [
        "sample_protocol()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tfuqi41lItnq"
      },
      "source": [
        "🌞 <font color='orange'>**Exercises**:</font>\n",
        "\n",
        "**Note** - Do these exercises manually, do *not* use your AI agent yet.\n",
        "\n",
        "1. Watch the opentron protocol designer [video](https://support.opentrons.com/s/article/How-to-write-a-basic-protocol-in-Protocol-Designer) to familiarize yourself with the robot and the environment. We're going to use the Python API directly rather than the `Protocol Designer` GUI. After watching the video, what do you think the protocol above is doing? Write a step-by-step plain text protocol that corresponds to what you think the protocol does.\n",
        "\n",
        "2. What do the `location` designations (e.g. `D1` and `D2`) in the script correspond to?\n",
        "\n",
        "3. Now familiarize yourself with the opentron [API](https://docs.opentrons.com/v2/) and pay special attention to the [Hardware Modules](https://docs.opentrons.com/v2/new_modules.html#) and the [Labware Library](https://labware.opentrons.com/). What is the difference between `Hardware` and `Labware` in the context of the opentron API?\n",
        "\n",
        "4. Find the API names for the following pieces of hardware/labware:\n",
        "  - Thermocycler module\n",
        "  - Magnetic block\n",
        "  - GEB 96 Tip Rack 10 µL\n",
        "  - Thermo Scientific Nunc 96 Well Plate 1300 µL\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ya_NSjH_PIEs"
      },
      "source": [
        "---\n",
        "⭐ Double click to write down your answers here\n",
        "\n",
        "\n",
        "```\n",
        "Answer:\n",
        "\n",
        "1.\n",
        "\n",
        "2.\n",
        "\n",
        "3.\n",
        "\n",
        "4.\n",
        "\n",
        "```\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wxESoXfPfxP"
      },
      "source": [
        "🌞 <font color='orange'>**Exercises**:</font>\n",
        "\n",
        "You've been given a 96-well plate where column 1 contains 300$\\mu$L of sample in each well of the column. You want to perform a serial dilution at 1:10 dilution factors across each column. So column 1 will contain the sample, column 2 will contain the sample diluted at 1:10, column 3 will be another 1:10 dilution (so 1:100 from the original sample) etc. You have the following working parameters for the protocol:\n",
        "\n",
        "  - You are diluting the sample into water. You have a reservoir of water available to you on the opentron.\n",
        "  - You want the final dilution column to be a 1:1000000 dilution from the original sample.\n",
        "  - Use version 2.19 of the opentron API\n",
        "  - Use an 8 channel pipette.\n",
        "  - You can order the opentron to aspirate/dispense from the first (top) well of a column using the 8 channel pipette and it will do so for the entire column. E.g. aspirating from well \"A1\" with an 8 channel pipette will aspirate from all wells in column 1.\n",
        "  - Use the same set of pipette tips for the entire dilution. So you only have to pick up tips once and drop them once over the course of the entire protocol.\n",
        "\n",
        "\n",
        "Use a combination of ChatGPT and the opentron API documentation to write a protocol that will perform this serial dilution on an opentron Flex using version 2.19 of the API. The newest ChatGPT should be somewhat familiar with the opentron API and should be able to write opentron python code. However, you may want to give it an example script to give hints about the specific structure and syntax you are looking to generate. You may also have to revise your script by hand using a combination of ChatGPT and the API documentation.\n",
        "\n",
        "The protocol must simulate succesfully."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y81IVyOPWiGW"
      },
      "source": [
        "⭐ Write your answer in the code cell below and use the simulation cell below that to try the protocol"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TU0SW6UJQ6zt"
      },
      "outputs": [],
      "source": [
        "from opentrons.simulate import get_protocol_api\n",
        "\n",
        "# Create a ProtocolContext for the Flex robot\n",
        "protocol = get_protocol_api(\n",
        "    version=\"2.19\", robot_type=\"Flex\"  # API version 2.19  # Flex robot\n",
        ")\n",
        "print(\"Protocol API version:\", protocol.api_version)\n",
        "\n",
        "\n",
        "# ⭐ Load labware\n",
        "plate =\n",
        "tiprack =\n",
        "reservoir =\n",
        "trash =\n",
        "\n",
        "# ⭐ Load pipette\n",
        "pipette =\n",
        "\n",
        "# ⭐ Variables\n",
        "dilution_factor =\n",
        "num_of_dilutions =\n",
        "sample_volume =\n",
        "diluent_volume =\n",
        "\n",
        "# Pickup the pipette tips\n",
        "pipette.pick_up_tip()\n",
        "\n",
        "# Add diluent to columns 2 through 7 (270 µL in each well across all rows)\n",
        "for col in range(2, num_of_dilutions + 2):\n",
        "    # ⭐\n",
        "\n",
        "# Perform serial dilution across all rows in columns 1 to 6\n",
        "for col in range(1, num_of_dilutions + 1):\n",
        "    # ⭐ Transfer sample from current column to the next\n",
        "\n",
        "\n",
        "    # ⭐ Mix to ensure proper dilution\n",
        "\n",
        "\n",
        "# ⭐ Optional: Dispose of remaining sample from the last column to avoid overflow\n",
        "\n",
        "\n",
        "# Dispose of the tips\n",
        "pipette.drop_tip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Coding Agents with Gemini CLI\n",
        "\n",
        "In previous exercises you have worked with Gemini CLI and even built your own MCP tools. Each tool was designed for a specific purpose — for example, one tool to move a pipette, another to measure liquid, etc. This time, we take a different approach: instead of many small tools, you will get **one powerful coding agent**.\n",
        "\n",
        "A coding agent is an AI assistant that can write and run code step by step while remembering the current state. This means it can share the same Python context across multiple calls. For example, if you define a variable or create a function in one step, the agent can use it again later without redefining it. This is very different from traditional one-shot tools, which start from scratch each time.\n",
        "\n",
        "### One Tool, Many Tasks\n",
        "\n",
        "Normally, MCP tools are built for a single action. But with a coding agent, you only need **one tool**:\n",
        "\n",
        "```python\n",
        "@mcp.tool\n",
        "def run_python(code):\n",
        "    exec(code, {\"pipette\": pipette})\n",
        "```\n",
        "\n",
        "Here, the tool accepts any Python code as input and executes it. Because the execution environment has access to objects like `pipette`, you can write different code snippets to control simulated labware — from aspirating liquid, to dispensing, to automating whole protocols. The same tool can therefore handle a wide range of tasks.\n",
        "\n",
        "\n",
        "### The `exec` Function in Python\n",
        "\n",
        "The key to making this possible is Python’s built-in `exec` function.\n",
        "\n",
        "`exec` takes a string of Python code and runs it as if you had typed it directly into the program.\n",
        "\n",
        "For example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10\n"
          ]
        }
      ],
      "source": [
        "code = \"\"\"\n",
        "x = 5\n",
        "print(x * 2)\n",
        "\"\"\"\n",
        "\n",
        "exec(code)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can also give `exec` a **context** (a dictionary of variables and objects) where the code will run:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10\n"
          ]
        }
      ],
      "source": [
        "x = 5\n",
        "\n",
        "code = \"print(x * 2)\"\n",
        "\n",
        "exec(code, {\"x\": x})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This means any code you pass in can directly use objects without having to create it again. In your case, the context includes the labware and intruments you have already set up, like the `plate`, `tiprack`, `pipette` or `trash`.\n",
        "\n",
        "For example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/nilsm/.opentrons/robot_settings.json not found. Loading defaults\n",
            "Belt calibration not found.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Picked up tip\n",
            "Aspirated 10uL from A1\n",
            "Dispensed 10uL to A2\n",
            "Dropped tip\n"
          ]
        }
      ],
      "source": [
        "protocol = get_protocol_api(version=\"2.19\", robot_type=\"Flex\")\n",
        "\n",
        "plate = protocol.load_labware(\n",
        "    load_name=\"corning_96_wellplate_360ul_flat\", location=\"D1\"\n",
        ")\n",
        "tiprack_1 = protocol.load_labware(\n",
        "    load_name=\"opentrons_flex_96_tiprack_200ul\", location=\"D2\"\n",
        ")\n",
        "trash = protocol.load_trash_bin(location=\"D3\")\n",
        "\n",
        "pipette = protocol.load_instrument(\n",
        "    instrument_name=\"flex_1channel_1000\",\n",
        "    mount=\"left\",\n",
        "    tip_racks=[tiprack_1],\n",
        ")\n",
        "\n",
        "\n",
        "def run_python(code):\n",
        "    exec(\n",
        "        # Execute the provided Python code\n",
        "        code,\n",
        "        # Provide access to the protocol objects\n",
        "        {\n",
        "            \"plate\": plate,\n",
        "            \"tiprack_1\": tiprack_1,\n",
        "            \"trash\": trash,\n",
        "            \"pipette\": pipette,\n",
        "        },\n",
        "    )\n",
        "\n",
        "# Example usage: run a simple pipetting command\n",
        "code = \"\"\"\n",
        "pipette.pick_up_tip()\n",
        "print(\"Picked up tip\")\n",
        "pipette.aspirate(10, plate[\"A1\"])\n",
        "print(\"Aspirated 10uL from A1\")\n",
        "pipette.dispense(10, plate[\"A2\"])\n",
        "print(\"Dispensed 10uL to A2\")\n",
        "pipette.drop_tip()\n",
        "print(\"Dropped tip\")\n",
        "\"\"\"\n",
        "\n",
        "run_python(code)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Why Coding Agents?\n",
        "\n",
        "With this approach, you no longer need to design a separate MCP tool for every single lab action. Instead:\n",
        "\n",
        "* The coding agent uses the `run_python` tool as a **universal interface**.\n",
        "* You can focus on **how to communicate with the agent**: writing clear instructions (in `Gemini.md`) and guiding it step by step to complete lab automation tasks.\n",
        "* The agent can remember and build on previous steps, which makes it powerful for scripting longer workflows.\n",
        "\n",
        "\n",
        "👉 In this lab, your task will be to design good instructions for the agent and practice telling it what code to run in order to automate robotic lab protocols.\n",
        "\n",
        "\n",
        "### Hypha to connect your MCP tool to Gemini CLI\n",
        "\n",
        "\n",
        "# TODO: add a brief explaination of hypha rpc\n",
        "\n",
        "---\n",
        "\n",
        "Full implementation of the code interpreter below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import ast\n",
        "import io\n",
        "import traceback\n",
        "from contextlib import redirect_stderr, redirect_stdout\n",
        "from typing import Any, Dict, Optional\n",
        "\n",
        "from hypha_rpc import connect_to_server\n",
        "from hypha_rpc.utils.schema import schema_function\n",
        "from pydantic import Field\n",
        "\n",
        "# Global variable to store lab objects\n",
        "LAB_OBJECTS = {}\n",
        "\n",
        "@schema_function\n",
        "def run_python(\n",
        "    code: str = Field(..., description=\"Python source code to execute.\"),\n",
        "    context: Optional[Dict[str, Any]] = Field(\n",
        "        default=None,\n",
        "        description=\"Optional dictionary of variables to preload into the execution environment.\",\n",
        "    ),\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Execute Python code and return combined stdout, stderr, result, or error as a single string.\n",
        "    Useful for print-style outputs where we want to avoid JSON encoding issues.\n",
        "    \"\"\"\n",
        "    # Print the code being executed\n",
        "    print(\"Executing code:\")\n",
        "    print(\"```python\")\n",
        "    print(code)\n",
        "    print(\"```\")\n",
        "    print(\"\\nOutput:\")\n",
        "    \n",
        "    context = {} if context is None else dict(context)\n",
        "\n",
        "    # Add lab objects to context\n",
        "    if LAB_OBJECTS is not None:\n",
        "        context.update(LAB_OBJECTS)\n",
        "\n",
        "    try:\n",
        "        tree = ast.parse(code, mode=\"exec\")\n",
        "    except SyntaxError as e:\n",
        "        error_msg = f\"SyntaxError: {e}\"\n",
        "        print(error_msg)\n",
        "        return error_msg\n",
        "\n",
        "    # Detect last expression for REPL-style return\n",
        "    capture_result = False\n",
        "    if tree.body and isinstance(tree.body[-1], ast.Expr):\n",
        "        capture_result = True\n",
        "        last_expr = tree.body[-1].value\n",
        "        tree.body[-1] = ast.Assign(\n",
        "            targets=[ast.Name(id=\"_ai_result\", ctx=ast.Store())],\n",
        "            value=last_expr,\n",
        "        )\n",
        "        ast.fix_missing_locations(tree)\n",
        "\n",
        "    code_obj = compile(tree, filename=\"<agent-code>\", mode=\"exec\")\n",
        "\n",
        "    f_stdout, f_stderr = io.StringIO(), io.StringIO()\n",
        "    try:\n",
        "        with redirect_stdout(f_stdout), redirect_stderr(f_stderr):\n",
        "            exec(code_obj, context)\n",
        "        result = context.get(\"_ai_result\") if capture_result else None\n",
        "        out = f_stdout.getvalue()\n",
        "        err = f_stderr.getvalue()\n",
        "        \n",
        "        # Build the complete output string\n",
        "        output = \"\"\n",
        "        if out:\n",
        "            output += out\n",
        "        if err:\n",
        "            output += f\"Stderr:\\n{err}\"\n",
        "        if result is not None:\n",
        "            output += f\"Result: {result!r}\"\n",
        "            \n",
        "        # Print the output\n",
        "        print(output)\n",
        "        return output\n",
        "    except Exception as e:\n",
        "        error_msg = f\"Error: {type(e).__name__}\\n{traceback.format_exc()}\"\n",
        "        print(error_msg)\n",
        "        return error_msg\n",
        "\n",
        "async def register_mcp_service(lab_objects: Dict[str, Any]):\n",
        "    \"\"\"\n",
        "    Register the Python code execution service with Hypha.\n",
        "    \"\"\"\n",
        "    global LAB_OBJECTS\n",
        "    LAB_OBJECTS = lab_objects\n",
        "    \n",
        "    # Register the service with Hypha\n",
        "    server = await connect_to_server({\"server_url\": \"https://hypha.aicell.io\"})\n",
        "    svc = await server.register_service(\n",
        "        {\n",
        "            \"id\": \"python-interpreter\",\n",
        "            \"name\": \"Python Interpreter\",\n",
        "            \"description\": \"Execute Python code with optional context; captures stdout, stderr, and last expression result.\",\n",
        "            \"config\": {\n",
        "                # Make the service public so it can be used by anyone\n",
        "                \"visibility\": \"public\"\n",
        "            },\n",
        "            # Register the function directly (not wrapped with partial)\n",
        "            \"run_python\": run_python,\n",
        "        }\n",
        "    )\n",
        "    \n",
        "    print(\"========================================\\n\")\n",
        "    print(\"Copy this MCP service URL to your Gemini `settings.json`:\\n\")\n",
        "    print(f\"https://hypha.aicell.io/{server.config.workspace}/mcp/{svc.id.split('/')[1]}/mcp\\n\")\n",
        "    print(\"========================================\\n\")\n",
        "\n",
        "    print(\"You can test the service function using this url:\")\n",
        "    print(f\"https://hypha.aicell.io/{server.config.workspace}/services/{svc.id.split('/')[1]}/run_python?code=print('hi')\\n\")\n",
        "    print(\"Note: Make sure to copy the full URL above!\")\n",
        "\n",
        "    # This will keep the service running forever\n",
        "    await server.serve()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yK9Sx8kshXIk"
      },
      "source": [
        "# Automating a real-life protocol\n",
        "\n",
        "Now we're going to explore how we can use the combination of lab robotics and LLMs to (partly) reproduce a real-world protocol.\n",
        "\n",
        "Our protocol will come from this [paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3185615/) testing the effects of various antifungal compounds on the formation of yeast biofilms.\n",
        "\n",
        "We will see how we can speed the process of experimentation using the tools we've been learning about.\n",
        "\n",
        "Watch the entire protocol [video](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3185615/bin/jove-44-2287-pmcvs_normal.mp4) to understand the purpose of the protocol and the steps involved."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usDFaSjDh9ve"
      },
      "source": [
        "🌞 <font color='orange'>**Exercise**:</font>\n",
        "\n",
        "Say you've performed the protocol by hand up until the point of setting up the plate with yeast for biofilm formation (2:49 in the video). You now have your yeast culture prepared and a 96-well plate ready to use.\n",
        "\n",
        "Choose the lab equipment you'll have to use from the opentron hardware/labware lists and use appropriate prompts to ChatGPT to create a script that will perform the protocol steps in the video outlined from 2:49 to 3:06 using an opentron Flex. You can make the following assumptions:\n",
        "\n",
        "- You have prepared 80mL of diluted yeast sample and have transferred it to an appropriate reservoir.\n",
        "- At the end of this script run, you'll lid the plate and parafilm it by hand.\n",
        "- Use version 2.19 of the opentron API.\n",
        "- Use an 8 channel pipette.\n",
        "- You can order the opentron to aspirate/dispense from the first (top) well of a column using the 8 channel pipette and it will do so for the entire column. E.g. aspirating from well \"A1\" with an 8 channel pipette will aspirate from all wells in column 1.\n",
        "- Use the same set of pipette tips for the entire dilution. So you only have to pick up tips once and drop them once over the course of the entire protocol.\n",
        "\n",
        "Simulate the protocol and make sure it runs correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from opentrons.simulate import get_protocol_api\n",
        "\n",
        "# Setup Opentrons protocol and labware/instrument objects\n",
        "protocol = get_protocol_api(version=\"2.19\", robot_type=\"Flex\")\n",
        "\n",
        "# ⭐ Load labware\n",
        "plate =\n",
        "tiprack_1 =\n",
        "trash =\n",
        "# Define other labware as needed\n",
        "\n",
        "# ⭐ Load instruments\n",
        "pipette =\n",
        "# Define other instruments as needed\n",
        "\n",
        "lab_objects = {\n",
        "    \"protocol\": protocol,\n",
        "    \"plate\": plate,\n",
        "    \"tiprack_1\": tiprack_1,\n",
        "    \"trash\": trash,\n",
        "    \"pipette\": pipette,\n",
        "    # ⭐ Add other labware/instruments here\n",
        "}\n",
        "\n",
        "await register_mcp_service(lab_objects)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Write a GEMINI.md file\n",
        "* Add MCP tool to Gemini settings.json\n",
        "* Start Gemini CLI with the MCP tool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Work on  VS Code Tunnel\n",
        "\n",
        "To work on your MCP tools, we recommend to switch to VS Code for better writing and debugging of your code. To still use Google Colab's free computing resources while enjoying the benefits of VS Code, you can install the VS Code Tunnel. This creates a secure connection between your Colab session and your local VS Code application, allowing you to edit files and run code directly within VS Code, while the processing happens in your Colab notebook. In addition, it will allow you to continue accessing all packages you installed in the current notebook.\n",
        "\n",
        "To install the VS Code Tunnel, click the **Terminal** button in the bottom of this page to open a terminal window.\n",
        "\n",
        "Then run the command below in the terminal to install the VS Code Tunnel:\n",
        "```\n",
        "curl -Lk 'https://code.visualstudio.com/sha/download?build=stable&os=cli-alpine-x64' --output vscode_cli.tar.gz\n",
        "tar -xf vscode_cli.tar.gz\n",
        "```\n",
        "\n",
        "### Start VS Code Tunnel\n",
        "\n",
        "After downloading the VS Code CLI, in the terminal, type:\n",
        "```\n",
        "./code tunnel\n",
        "```\n",
        "\n",
        "Then follow the instructions, use your arrow keys to select `❯ GitHub Account`, then you will see something like:\n",
        "\n",
        "> To grant access to the server, please log into https://github.com/login/device and use code B6BB-23AA\n",
        "\n",
        "You should now copy the url and open in a new browser tab, then copy the device code to login, you will need to approve the access to your github account then return to this terminal.\n",
        "\n",
        "Then you will see something like, and type e.g. `colab` for the name to identify this machine:\n",
        "> ? What would you like to call this machine? (30d8d79434a3) › colab\n",
        "\n",
        "After that you should see:\n",
        "> Open this link in your browser https://vscode.dev/tunnel/colab/content\n",
        "\n",
        "Now visit the link and you should get the vscode session where you will work on.\n",
        "\n",
        "> Switch to the Module6 Folder\n",
        "Open a terminal in VS Code (View -> Terminal). Move working directory to folder on Google Drive and use this folder as your workspace. This is a crucial step.\n",
        "\n",
        "```\n",
        "cd /content/drive/MyDrive/DDLS-Course/Module6/\n",
        "code .\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4htB2GgadXm"
      },
      "source": [
        "🌞 <font color='orange'>**Exercise 2(Optional)**:</font>\n",
        "\n",
        "For running this task, you will need to terminate last running cell first.\n",
        "\n",
        "Now say you've continued the protocol, performing the incubation and washes by hand. You have prepared a stock solution of 1,024 $\\mu$g/mL fluconazole and a stock solution of buffered RPMI 1640 medium.\n",
        "\n",
        "Choose the lab equipment you'll have to use from the opentron hardware/labware lists and use appropriate prompts to ChatGPT to create a script that will perform the protocol steps for Antifungal Susceptibility Testing of Biofilms (3:57 to 5:04). You can make the following assumptions:\n",
        "\n",
        "- You have prepared 80mL of fluconazole and 80mL of media and have transferred them to appropriate reservoirs.\n",
        "- At the end of this script run, you'll lid the plate and parafilm it by hand.\n",
        "- Use version 2.19 of the opentron API.\n",
        "- Use an 8 channel pipette.\n",
        "- You can order the opentron to aspirate/dispense from the first (top) well of a column using the 8 channel pipette and it will do so for the entire column. E.g. aspirating from well \"A1\" with an 8 channel pipette will aspirate from all wells in column 1.\n",
        "- Use a *different* set of pipette tips for (1) dispensing the antifungal (2) dispensing the medium (3) performing the dilutions. So you should use a total of three set of tips (pick up / drop off operations) over the course of the protocol.\n",
        "\n",
        "Simulate the protocol and make sure it runs correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uoFrM14pcv8"
      },
      "outputs": [],
      "source": [
        "from opentrons.simulate import get_protocol_api\n",
        "\n",
        "# Setup Opentrons protocol and labware/instrument objects\n",
        "protocol = get_protocol_api(version=\"2.19\", robot_type=\"Flex\")\n",
        "\n",
        "# ⭐ Load labware\n",
        "plate =\n",
        "tiprack_1 =\n",
        "trash =\n",
        "# Define other labware as needed\n",
        "\n",
        "# ⭐ Load instruments\n",
        "pipette =\n",
        "# Define other instruments as needed\n",
        "\n",
        "lab_objects = {\n",
        "    \"protocol\": protocol,\n",
        "    \"plate\": plate,\n",
        "    \"tiprack_1\": tiprack_1,\n",
        "    \"trash\": trash,\n",
        "    \"pipette\": pipette,\n",
        "    # ⭐ Add other labware/instruments here\n",
        "}\n",
        "\n",
        "await register_mcp_service(lab_objects)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLyEyTJtpm1s"
      },
      "source": [
        "🌞 <font color='orange'>**Discussion Exercises**:</font>\n",
        "\n",
        "1. What were the benefits of using ChatGPT for writing these protocols? What was it able to do succesfully and what did you have to do by hand?\n",
        "\n",
        "2. Look at the entire protocol from the paper [video](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3185615/bin/jove-44-2287-pmcvs_normal.mp4) again. What additional portions do you think you would be able to automate on the opentron? What parts could you automate with more advanced robotic hardware? What parts (if any) are do you think can't be reliably done using robotics?\n",
        "\n",
        "3. Looking at the output of your simulations, can you propose a way in which you could have LLMs write protocols then use the simulation output to revise the protocol accordingly?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSPdLmagJmQT"
      },
      "source": [
        "---\n",
        "⭐ Double click to write down your answers here\n",
        "\n",
        "\n",
        "```\n",
        "Answer:\n",
        "\n",
        "1.\n",
        "\n",
        "2.\n",
        "\n",
        "3.\n",
        "\n",
        "```\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ddls-m6",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
