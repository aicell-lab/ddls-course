{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8bf51c3299d844e08d627b962509583b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_069143db2cc84f2d92477a2bb99adc41",
              "IPY_MODEL_9e05ed088fae457a8b3ade4e73ad5703",
              "IPY_MODEL_2e7d375404f64a65917b5b8dd5bb9d4a"
            ],
            "layout": "IPY_MODEL_972f9ef278384859ac50546a5370b4ea"
          }
        },
        "069143db2cc84f2d92477a2bb99adc41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f28516dbd93749159c1a8c060e86bdfd",
            "placeholder": "​",
            "style": "IPY_MODEL_740260da6b3d4204bc88e8bf2d4630f8",
            "value": " 18%"
          }
        },
        "9e05ed088fae457a8b3ade4e73ad5703": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91d3817735b14c589dcdcc1cca14bf67",
            "max": 55,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0d87b7fc82d549deb3aa7120488d7958",
            "value": 10
          }
        },
        "2e7d375404f64a65917b5b8dd5bb9d4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccd329ac882448b39359a4fd56e5ed75",
            "placeholder": "​",
            "style": "IPY_MODEL_cc462b9368ce410392ae5f3a95797698",
            "value": " 10/55 [elapsed: 00:19 remaining: 01:20]"
          }
        },
        "972f9ef278384859ac50546a5370b4ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f28516dbd93749159c1a8c060e86bdfd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "740260da6b3d4204bc88e8bf2d4630f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91d3817735b14c589dcdcc1cca14bf67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d87b7fc82d549deb3aa7120488d7958": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ccd329ac882448b39359a4fd56e5ed75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc462b9368ce410392ae5f3a95797698": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pc5-mbsX9PZC"
      },
      "source": [
        "# AlphaFold2 for protein structure prediction\n",
        "\n",
        "## Computer lab notebook for [DDLS 2023 course](https://ddls.aicell.io/course/ddls-2023), module 6.\n",
        "\n",
        "In this lab, we will analyze the alphafold neural network in order to understand how the network reasons about protein structure inference from protein sequence data. To make competent inferences fast, be sure to use the GPU environment. One inference step should take around 1 minute. For more information about the network and the wrapper we are using to speed up the calculations, you are welcome to review the following references:\n",
        "\n",
        "This notebook modifies deepmind's [original notebook](https://colab.research.google.com/github/deepmind/alphafold/blob/main/notebooks/AlphaFold.ipynb) (**before AlphaFold-Multimer existed**) to add experimental support for modeling complexes (both homo and hetero-oligomers), option to run MMseqs2 instead of Jackhmmer for MSA generation and advanced functionality.\n",
        "\n",
        "See [ColabFold](https://github.com/sokrypton/ColabFold/) for other related notebooks\n",
        "\n",
        "[Mirdita M, Schütze K, Moriwaki Y, Heo L, Ovchinnikov S, Steinegger M. ColabFold: Making protein folding accessible to all.\n",
        "*Nature Methods*, 2022](https://www.nature.com/articles/s41592-022-01488-1)\n",
        "\n",
        "DO remember that this is an advanced lab and you are expected to, among other things, find information on your own, devise strategies for analysis, write your own code in the framework of this notebook, and provide discussion and answers to the questions to the 2 tasks. Good luck!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woIxeCPygt7K",
        "cellView": "form",
        "outputId": "b502e80f-91f8-4d8f-c8a4-0e7cf0917f90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "8bf51c3299d844e08d627b962509583b",
            "069143db2cc84f2d92477a2bb99adc41",
            "9e05ed088fae457a8b3ade4e73ad5703",
            "2e7d375404f64a65917b5b8dd5bb9d4a",
            "972f9ef278384859ac50546a5370b4ea",
            "f28516dbd93749159c1a8c060e86bdfd",
            "740260da6b3d4204bc88e8bf2d4630f8",
            "91d3817735b14c589dcdcc1cca14bf67",
            "0d87b7fc82d549deb3aa7120488d7958",
            "ccd329ac882448b39359a4fd56e5ed75",
            "cc462b9368ce410392ae5f3a95797698"
          ]
        }
      },
      "source": [
        "#@title Install software\n",
        "#@markdown Please execute this cell by pressing the _Play_ button\n",
        "#@markdown on the left. We first need to install the required software to be able to analyze the results.\n",
        "\n",
        "# setup device\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "import jax\n",
        "\n",
        "try:\n",
        "  # check if TPU is available\n",
        "  import jax.tools.colab_tpu\n",
        "  jax.tools.colab_tpu.setup_tpu()\n",
        "  print('Running on TPU')\n",
        "  DEVICE = \"tpu\"\n",
        "except:\n",
        "  if jax.local_devices()[0].platform == 'cpu':\n",
        "    print(\"WARNING: no GPU detected, will be using CPU\")\n",
        "    DEVICE = \"cpu\"\n",
        "  else:\n",
        "    print('Running on GPU')\n",
        "    DEVICE = \"gpu\"\n",
        "    # disable GPU on tensorflow\n",
        "    tf.config.set_visible_devices([], 'GPU')\n",
        "\n",
        "from IPython.utils import io\n",
        "import subprocess\n",
        "import tqdm.notebook\n",
        "\n",
        "install_jackhmmer = True\n",
        "GIT_REPO = 'https://github.com/deepmind/alphafold'\n",
        "COLAB_REPO = 'https://github.com/sokrypton/ColabFold.git'\n",
        "SOURCE_URL = 'https://storage.googleapis.com/alphafold/alphafold_params_2021-07-14.tar'\n",
        "PARAMS_DIR = './alphafold/data/params'\n",
        "PARAMS_PATH = os.path.join(PARAMS_DIR, os.path.basename(SOURCE_URL))\n",
        "TQDM_BAR_FORMAT = '{l_bar}{bar}| {n_fmt}/{total_fmt} [elapsed: {elapsed} remaining: {remaining}]'\n",
        "TMP_DIR = \"tmp\"\n",
        "os.makedirs(TMP_DIR, exist_ok=True)\n",
        "\n",
        "# if not already installed\n",
        "total = 55\n",
        "with tqdm.notebook.tqdm(total=total, bar_format=TQDM_BAR_FORMAT) as pbar:\n",
        "    #if not os.path.isdir(\"alphafold\"):\n",
        "    # download alphafold code\n",
        "    os.system(f\"git clone {GIT_REPO} alphafold; cd alphafold; git checkout 1d43aaff941c84dc56311076b58795797e49107b\")\n",
        "    os.system(f\"git clone {COLAB_REPO} ColabFold\")\n",
        "    # apply patches\n",
        "    sys.path.append(f'ColabFold/beta/')\n",
        "    if 'ColabFold/beta' not in sys.path:\n",
        "        sys.path.append('ColabFold/beta')\n",
        "    for name in [\"model\",\"modules\",\"folding\",\"config\"]:\n",
        "       with open(f'ColabFold/beta/{name}.patch','r') as file:\n",
        "           f=file.readlines()\n",
        "       w = open(f'alphafold/alphafold/model/{name}.py','w')\n",
        "       for line in f:\n",
        "           w.write(line)\n",
        "       w.close()\n",
        "    with open(f'ColabFold/beta/protein.patch','r') as file:\n",
        "         f=file.readlines()\n",
        "    w = open(f'alphafold/alphafold/common/protein.py','w')\n",
        "    for line in f:\n",
        "        w.write(line)\n",
        "    w.close()\n",
        "    pbar.update(4)\n",
        "    os.system(f\"pip install biopython dm-haiku==0.0.5 ml-collections py3Dmol\")\n",
        "    pbar.update(6)\n",
        "\n",
        "    # download model params (speedup from kaczmarj)\n",
        "    os.system(f\"mkdir --parents {PARAMS_DIR}\")\n",
        "    os.system(f\"curl -fsSL {SOURCE_URL} | tar x -C {PARAMS_DIR}\")\n",
        "    pbar.update(14+27)\n",
        "\n",
        "    # install hhsuite\n",
        "    os.system(f\"curl -fsSL https://github.com/soedinglab/hh-suite/releases/download/v3.3.0/hhsuite-3.3.0-SSE2-Linux.tar.gz | tar xz -C {TMP_DIR}/\")\n",
        "\n",
        "    # install jackhmmer\n",
        "    if install_jackhmmer:\n",
        "      os.system(f\"sudo apt install --quiet --yes hmmer\")\n",
        "      pbar.update(3)\n",
        "\n",
        "      # create a ramdisk to store a database chunk to make Jackhmmer run fast.\n",
        "      os.system(f\"sudo mkdir -m 777 --parents /tmp/ramdisk\")\n",
        "      os.system(f\"sudo mount -t tmpfs -o size=9G ramdisk /tmp/ramdisk\")\n",
        "      pbar.update(1)\n",
        "\n",
        "    else:\n",
        "      pbar.update(4)\n",
        "\n",
        "  #else:\n",
        "  #  pbar.update(55)\n",
        "\n",
        "########################################################################################\n",
        "# --- Python imports ---\n",
        "if 'alphafold' not in sys.path:\n",
        "  sys.path.append('alphafold')\n",
        "if 'ColabFold/beta' not in sys.path:\n",
        "  sys.path.append('ColabFold/beta')\n",
        "\n",
        "if f\"{TMP_DIR}/bin\" not in os.environ['PATH']:\n",
        "  os.environ['PATH'] += f\":{TMP_DIR}/bin:{TMP_DIR}/scripts\"\n",
        "\n",
        "import colabfold as cf\n",
        "import colabfold_alphafold as cf_af\n",
        "\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on GPU\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/55 [elapsed: 00:00 remaining: ?]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8bf51c3299d844e08d627b962509583b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rowN0bVYLe9n",
        "cellView": "form"
      },
      "source": [
        "#@title Enter the amino acid sequence to fold ⬇️\n",
        "import re\n",
        "\n",
        "# define sequence\n",
        "sequence = 'PIAQIHILEGRSDEQKETLIREVSEAISRSLDAPLTSVRVIITEMAKGHFGIGGELASK' #@param {type:\"string\"}\n",
        "jobname = \"test\" #@param {type:\"string\"}\n",
        "homooligomer =  \"1\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown - `sequence` Specify protein sequence to be modelled.\n",
        "#@markdown  - Use `/` to specify intra-protein chainbreaks (for trimming regions within protein).\n",
        "#@markdown  - Use `:` to specify inter-protein chainbreaks (for modeling protein-protein hetero-complexes).\n",
        "#@markdown  - For example, sequence `AC/DE:FGH` will be modelled as polypeptides: `AC`, `DE` and `FGH`. A seperate MSA will be generates for `ACDE` and `FGH`.\n",
        "#@markdown    If `pair_msa` is enabled, `ACDE`'s MSA will be paired with `FGH`'s MSA.\n",
        "#@markdown - `homooligomer` Define number of copies in a homo-oligomeric assembly.\n",
        "#@markdown  - Use `:` to specify different homooligomeric state (copy numer) for each component of the complex.\n",
        "#@markdown  - For example, **sequence:**`ABC:DEF`, **homooligomer:** `2:1`, the first protein `ABC` will be modeled as a homodimer (2 copies) and second `DEF` a monomer (1 copy).\n",
        "\n",
        "I = cf_af.prep_inputs(sequence, jobname, homooligomer, clean=IN_COLAB)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITcPnLkLuDDE",
        "cellView": "form"
      },
      "source": [
        "#@title Search against genetic databases\n",
        "#@markdown Once this cell has been executed, you will see\n",
        "#@markdown statistics about the multiple sequence alignment\n",
        "#@markdown (MSA) that will be used by AlphaFold. In particular,\n",
        "#@markdown you’ll see how well each residue is covered by similar\n",
        "#@markdown sequences in the MSA.\n",
        "#@markdown (Note that the search against databases and the actual prediction can take some time, from minutes to hours, depending on the length of the protein and what type of GPU you are allocated by Colab.)\n",
        "\n",
        "#@markdown ---\n",
        "msa_method = \"mmseqs2\" #@param [\"mmseqs2\",\"jackhmmer\",\"single_sequence\",\"precomputed\"]\n",
        "#@markdown - `mmseqs2` - FAST method from [ColabFold](https://github.com/sokrypton/ColabFold)\n",
        "#@markdown - `jackhmmer` - default method from Deepmind (SLOW, but may find more/less sequences).\n",
        "#@markdown - `single_sequence` - use single sequence input\n",
        "#@markdown - `precomputed` If you have previously run this notebook and saved the results,\n",
        "#@markdown you can skip this step by uploading\n",
        "#@markdown the previously generated  `prediction_?????/msa.pickle`\n",
        "\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown **custom msa options**\n",
        "add_custom_msa = False #@param {type:\"boolean\"}\n",
        "msa_format = \"fas\" #@param [\"fas\",\"a2m\",\"a3m\",\"sto\",\"psi\",\"clu\"]\n",
        "#@markdown - `add_custom_msa` - If enabled, you'll get an option to upload your custom MSA in the specified `msa_format`. Note: Your MSA will be supplemented with those from 'mmseqs2' or 'jackhmmer', unless `msa_method` is set to 'single_sequence'.\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown **pair msa options**\n",
        "\n",
        "#@markdown Experimental option for protein complexes. Pairing currently only supported for proteins in same operon (prokaryotic genomes).\n",
        "pair_mode = \"unpaired\" #@param [\"unpaired\",\"unpaired+paired\",\"paired\"] {type:\"string\"}\n",
        "#@markdown - `unpaired` - generate seperate MSA for each protein.\n",
        "#@markdown - `unpaired+paired` - attempt to pair sequences from the same operon within the genome.\n",
        "#@markdown - `paired` - only use sequences that were sucessfully paired.\n",
        "\n",
        "#@markdown Options to prefilter each MSA before pairing. (It might help if there are any paralogs in the complex.)\n",
        "pair_cov = 50 #@param [0,25,50,75,90] {type:\"raw\"}\n",
        "pair_qid = 20 #@param [0,15,20,30,40,50] {type:\"raw\"}\n",
        "#@markdown - `pair_cov` prefilter each MSA to minimum coverage with query (%) before pairing.\n",
        "#@markdown - `pair_qid` prefilter each MSA to minimum sequence identity with query (%) before pairing.\n",
        "\n",
        "# --- Search against genetic databases ---\n",
        "\n",
        "I = cf_af.prep_msa(I, msa_method, add_custom_msa, msa_format,\n",
        "                   pair_mode, pair_cov, pair_qid, TMP_DIR=TMP_DIR)\n",
        "mod_I = I\n",
        "\n",
        "if len(I[\"msas\"][0]) > 1:\n",
        "  plt = cf.plot_msas(I[\"msas\"], I[\"ori_sequence\"])\n",
        "  plt.savefig(os.path.join(I[\"output_dir\"],\"msa_coverage.png\"), bbox_inches = 'tight', dpi=200)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYIjwa1VXeeW",
        "cellView": "form"
      },
      "source": [
        "#@title Filter options (optional)\n",
        "trim = \"\" #@param {type:\"string\"}\n",
        "trim_inverse = False #@param {type:\"boolean\"}\n",
        "#@markdown - Use `trim` to specify regions to trim. For example: `trim:5-9,20` will remove positions 5,6,7,8,9 and 20.\n",
        "#@markdown  - For complexes, you can use `trim:A1-A3,B5-B7` to remove positions 1,2,3 in 1st protein and positions 5,6,7 in 2nd protein.\n",
        "#@markdown  - Note: This function is 1-indexed, meaning the first position is 1, not 0.\n",
        "#@markdown  - To specify regions to keep instead of trim, enable `trim_inverse`\n",
        "cov = 0 #@param [0,25,50,75,90,95] {type:\"raw\"}\n",
        "qid = 0 #@param [0,15,20,25,30,40,50] {type:\"raw\"}\n",
        "#@markdown - `cov` minimum coverage with query (%)\n",
        "#@markdown - `qid` minimum sequence identity with query (%)\n",
        "\n",
        "mod_I = cf_af.prep_filter(I, trim, trim_inverse, cov, qid)\n",
        "\n",
        "if I[\"msas\"] != mod_I[\"msas\"]:\n",
        "  plt.figure(figsize=(16,5),dpi=100)\n",
        "  plt.subplot(1,2,1)\n",
        "  plt.title(\"Sequence coverage (Before)\")\n",
        "  cf.plot_msas(I[\"msas\"], I[\"ori_sequence\"], return_plt=False)\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.title(\"Sequence coverage (After)\")\n",
        "  cf.plot_msas(mod_I[\"msas\"], mod_I[\"ori_sequence\"], return_plt=False)\n",
        "  plt.savefig(os.path.join(I[\"output_dir\"],\"msa_coverage.filtered.png\"), bbox_inches = 'tight', dpi=200)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQe3KeyTcv0n",
        "cellView": "form"
      },
      "source": [
        "#@title Run alphafold\n",
        "num_relax = \"None\"\n",
        "rank_by = \"pLDDT\"\n",
        "use_turbo = True\n",
        "max_msa = \"512:1024\"\n",
        "max_msa_clusters, max_extra_msa = [int(x) for x in max_msa.split(\":\")]\n",
        "\n",
        "#@markdown Before we run our alphafold prediction, we need to define a few options and variables. Have a look in the code to see the scope of parameters that need to be set. For instance, the parameter `use_turbo` introduces a few modifications (compile once, swap params, adjust max_msa) to speedup and reduce memory requirements. Disable for default behavior. Here is how you would implement the feature (see corresponding code block)\n",
        "show_images = True #@param {type:\"boolean\"}\n",
        "#@markdown - `show_images` To make things more exciting we show images of the predicted structures as they are being generated. (WARNING: the order of images displayed does not reflect any ranking).\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown **Sampling options**\n",
        "\n",
        "#@markdown There are two stochastic parts of the pipeline. Within the feature generation (choice of cluster centers) and within the model (dropout).\n",
        "#@markdown To get structure diversity, you can iterate through a fixed number of random_seeds (using `num_samples`) and/or enable dropout (using `is_training`).\n",
        "#@markdown To speed up the claculation on a GPU we only use the bare necessary options, such as only one sample and one model etc. If you were concerned with model quality, you would have to change\n",
        "#@markdown these parameters. When evaluating model quality and robustness though, this is less important.\n",
        "num_models = 1 #@param [1,2,3,4,5] {type:\"raw\"}\n",
        "use_ptm = True\n",
        "num_ensemble = 1\n",
        "max_recycles = 1\n",
        "is_training = False\n",
        "num_samples = 1\n",
        "#@markdown - `num_models` specify how many model params to try. (5 recommended, but we use 1 to speed up calculations)\n",
        "subsample_msa = True\n",
        "\n",
        "if not use_ptm and rank_by == \"pTMscore\":\n",
        "  print(\"WARNING: models will be ranked by pLDDT, 'use_ptm' is needed to compute pTMscore\")\n",
        "  rank_by = \"pLDDT\"\n",
        "\n",
        "# prep input features\n",
        "feature_dict = cf_af.prep_feats(mod_I, clean=IN_COLAB)\n",
        "Ls_plot = feature_dict[\"Ls\"]\n",
        "\n",
        "# prep model options\n",
        "opt = {\"N\":len(feature_dict[\"msa\"]),\n",
        "       \"L\":len(feature_dict[\"residue_index\"]),\n",
        "       \"use_ptm\":use_ptm,\n",
        "       \"use_turbo\":use_turbo,\n",
        "       \"max_recycles\":max_recycles,\n",
        "       \"tol\":0.0,\n",
        "       \"num_ensemble\":num_ensemble,\n",
        "       \"max_msa_clusters\":max_msa_clusters,\n",
        "       \"max_extra_msa\":max_extra_msa,\n",
        "       \"is_training\":is_training}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown **Task 1 - Evoformer Inference**\n",
        "\n",
        "#@markdown Begin with running one prediction of alphafold so that you see what the predicted structure for the given input sequence is.\n",
        "#@markdown Make sure to time how long the prediction (inference) of our sequence of interest takes so that you can make informed choices\n",
        "#@markdown about how many different parameters you can perturb in task 2. In this task, you will analyse how alphafold reasons about your sequence\n",
        "#@markdown across the evoformer blocks (see Figure 1.).\n",
        "\n",
        "#@markdown \\\n",
        "\n",
        "\n",
        "#@markdown |![](https://drive.google.com/uc?export=view&id=1V_kLp5rMBs6gnEXm4cFPp6X-8ISZv4TX)|\n",
        "#@markdown |:--:|\n",
        "#@markdown | <b>Figure 1. Overview of the entire alphafold network</b>|\n",
        "\n",
        "#@markdown \\\n",
        "\n",
        "#@markdown After having run the inference, the `outs` variable is a dictionary of all the model outputs. For each model N (you only have one)\n",
        "#@markdown and seed M (you still only have one), there is a key of the `outs` dictionary called *model_{N}_ptm_seed_{M-1}*. To access the results of the run,\n",
        "#@markdown you can find the pair representations in `outs[\"model_1_ptm_seed_0\"][\"representations\"][\"all\"]`. You will notice that the shape is `(48,r,r,c)`, where r,r,c is a single iteration of the pair representation\n",
        "\n",
        "#@markdown To evaluate the behaviour of the inference, you will have to create a plot that shows how and when alphafold converges on the final pair representation.\n",
        "#@markdown What are the characteristics of this function and how do you reason about its shape. What does this tell you about how alphafold makes the prediction?\n",
        "#@markdown ***Hint***: *Try to find a suitable metric to measure the difference between each tensor of shape `r,r,c` and plots its evolution across blocks*.\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown **Task 2 - Model Robustness**\n",
        "\n",
        "\n",
        "#@markdown For a relatively complex generative model such as alphafold, many different layers are all providing their own input on the final inference. But surely,\n",
        "#@markdown not all layers in the network are equally important. To understand which features are determined in each layer, and how robust the model is, a rudimentary option is\n",
        "#@markdown to perturb the parameters of the model. In this implementation, this is determined by the `user_perturbation` parameter, which is divided into scopes and parameter spaces, which correspond to\n",
        "#@markdown to all hierarchical layers in the network. To rationalize the effect of your chosen parameter space and scope, please connect any interesting layers with the processes described in figure 2.\n",
        "\n",
        "#@markdown |![](https://drive.google.com/uc?export=view&id=1mhW3ABAesd1MSUP7lEo8ZPTkO29OEd96)|\n",
        "#@markdown |:--:|\n",
        "#@markdown | <b>Figure 2. The most important network compartments (not individual layers) within the entire model.</b>|\n",
        "\n",
        "#@markdown To identify the names of each parameter space and corresponding scope, you can run the example script after your runner has been prepared (see code block below).\n",
        "#@markdown You are also expected to find a suitable value of the parameter_pertubation (too small doesn't do anything, too large destroys everything). It can be interpreted as the fraction f of total parameter magnitude M perturbed with a `N(0,f*M)` distribution.\n",
        "#@markdown ***Hint***: *Modify the user perturbation of a few select (or all, if time permits) layers by changing the `user_perturbation`\n",
        "#@markdown array in a for loop and plot the results (e.g. final contact map/distogram, which you can find in `outs`). You can preferably use the metric from the previous task.*\n",
        "#@markdown ```python\n",
        "#@markdown  for scope in runner[\"scopes\"].keys():\n",
        "#@markdown    for name in runner[\"scopes\"][scope].keys():\n",
        "#@markdown       print(scope,name)\n",
        "#@markdown ```\n",
        "scope = \"alphafold/alphafold_iteration/structure_module/fold_iteration/rigid_sidechain/input_projection\" #@param {type:\"string\"}\n",
        "parameter_space = \"weights\" #@param {type:\"string\"}\n",
        "parameter_perturbation = 0.0 #@param {type: \"raw\"}\n",
        "\n",
        "user_perturbation = [scope,parameter_space,parameter_perturbation]\n",
        "\n",
        "if use_turbo:\n",
        "  #if \"runner\" in dir():\n",
        "  #  # only recompile if options changed\n",
        "  #  runner = cf_af.prep_model_runner(opt, old_runner=runner,user_perturbation)\n",
        "  #else:\n",
        "  runner = cf_af.prep_model_runner(opt,user_perturbation=user_perturbation)\n",
        "else:\n",
        "  runner = None\n",
        "\n",
        "print(runner[\"message\"])\n",
        "\n",
        "\n",
        "\n",
        "###########################\n",
        "# run alphafold\n",
        "###########################\n",
        "\n",
        "outs, model_rank = cf_af.run_alphafold(feature_dict, opt, runner, num_models, num_samples, subsample_msa,\n",
        "                                       rank_by=rank_by, show_images=show_images,user_perturbation=user_perturbation)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown You can add your own code here :) .\n",
        "print(outs[\"model_1_ptm_seed_0\"][\"representations\"][\"all\"].shape)\n",
        "evoformer_num_updates = 48\n"
      ],
      "metadata": {
        "id": "Klkun6_5RvwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzK2Wve12GCk",
        "cellView": "form"
      },
      "source": [
        "#@title Extra outputs (optional).\n",
        "#@markdown Here you can find how to extract contacts, distograms, LDDT and other quantities that may be of interest to compare to each other.\n",
        "dpi =  100#@param {type:\"integer\"}\n",
        "save_to_txt = True #@param {type:\"boolean\"}\n",
        "save_pae_json = True #@param {type:\"boolean\"}\n",
        "#@markdown - save data used to generate contact and distogram plots below to text file (pae values can be found in json file if `use_ptm` is enabled)\n",
        "\n",
        "if use_ptm:\n",
        "  print(\"predicted alignment error\")\n",
        "  cf.plot_paes([outs[k][\"pae\"] for k in model_rank], Ls=Ls_plot, dpi=dpi)\n",
        "  plt.savefig(os.path.join(I[\"output_dir\"],f'predicted_alignment_error.png'), bbox_inches = 'tight', dpi=np.maximum(200,dpi))\n",
        "  plt.show()\n",
        "\n",
        "print(\"predicted contacts\")\n",
        "cf.plot_adjs([outs[k][\"adj\"] for k in model_rank], Ls=Ls_plot, dpi=dpi)\n",
        "plt.savefig(os.path.join(I[\"output_dir\"],f'predicted_contacts.png'), bbox_inches = 'tight', dpi=np.maximum(200,dpi))\n",
        "plt.show()\n",
        "\n",
        "print(\"predicted distogram\")\n",
        "cf.plot_dists([outs[k][\"dists\"] for k in model_rank], Ls=Ls_plot, dpi=dpi)\n",
        "plt.savefig(os.path.join(I[\"output_dir\"],f'predicted_distogram.png'), bbox_inches = 'tight', dpi=np.maximum(200,dpi))\n",
        "plt.show()\n",
        "\n",
        "print(\"predicted LDDT\")\n",
        "cf.plot_plddts([outs[k][\"plddt\"] for k in model_rank], Ls=Ls_plot, dpi=dpi)\n",
        "plt.savefig(os.path.join(I[\"output_dir\"],f'predicted_LDDT.png'), bbox_inches = 'tight', dpi=np.maximum(200,dpi))\n",
        "plt.show()\n",
        "\n",
        "def do_save_to_txt(filename, adj, dists, sequence):\n",
        "  adj = np.asarray(adj)\n",
        "  dists = np.asarray(dists)\n",
        "  L = len(adj)\n",
        "  with open(filename,\"w\") as out:\n",
        "    out.write(\"i\\tj\\taa_i\\taa_j\\tp(cbcb<8)\\tmaxdistbin\\n\")\n",
        "    for i in range(L):\n",
        "      for j in range(i+1,L):\n",
        "        if dists[i][j] < 21.68 or adj[i][j] >= 0.001:\n",
        "          line = f\"{i}\\t{j}\\t{sequence[i]}\\t{sequence[j]}\\t{adj[i][j]:.3f}\"\n",
        "          line += f\"\\t>{dists[i][j]:.2f}\" if dists[i][j] == 21.6875 else f\"\\t{dists[i][j]:.2f}\"\n",
        "          out.write(f\"{line}\\n\")\n",
        "\n",
        "for n,key in enumerate(model_rank):\n",
        "  if save_to_txt:\n",
        "    txt_filename = os.path.join(I[\"output_dir\"],f'rank_{n+1}_{key}.raw.txt')\n",
        "    do_save_to_txt(txt_filename,\n",
        "                   outs[key][\"adj\"],\n",
        "                   outs[key][\"dists\"],\n",
        "                   mod_I[\"full_sequence\"])\n",
        "\n",
        "  if use_ptm and save_pae_json:\n",
        "    pae = outs[key][\"pae\"]\n",
        "    max_pae = pae.max()\n",
        "    # Save pLDDT and predicted aligned error (if it exists)\n",
        "    pae_output_path = os.path.join(I[\"output_dir\"],f'rank_{n+1}_{key}_pae.json')\n",
        "    # Save predicted aligned error in the same format as the AF EMBL DB\n",
        "    rounded_errors = np.round(np.asarray(pae), decimals=1)\n",
        "    indices = np.indices((len(rounded_errors), len(rounded_errors))) + 1\n",
        "    indices_1 = indices[0].flatten().tolist()\n",
        "    indices_2 = indices[1].flatten().tolist()\n",
        "    pae_data = json.dumps([{\n",
        "        'residue1': indices_1,\n",
        "        'residue2': indices_2,\n",
        "        'distance': rounded_errors.flatten().tolist(),\n",
        "        'max_predicted_aligned_error': max_pae.item()\n",
        "    }],\n",
        "                          indent=None,\n",
        "                          separators=(',', ':'))\n",
        "    with open(pae_output_path, 'w') as f:\n",
        "      f.write(pae_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Riekgf0KQv_3",
        "cellView": "form"
      },
      "source": [
        "#@title Download prediction\n",
        "\n",
        "#@markdown Once this cell has been executed, a zip-archive with\n",
        "#@markdown the obtained prediction will be automatically downloaded\n",
        "#@markdown to your computer.\n",
        "\n",
        "# add settings file\n",
        "settings_path = os.path.join(I[\"output_dir\"],\"settings.txt\")\n",
        "with open(settings_path, \"w\") as text_file:\n",
        "  text_file.write(f\"notebook=https://colab.research.google.com/github/sokrypton/ColabFold/blob/main/beta/AlphaFold2_advanced_beta.ipynb\\n\")\n",
        "  text_file.write(f\"sequence={I['ori_sequence']}\\n\")\n",
        "  text_file.write(f\"msa_method={msa_method}\\n\")\n",
        "  if add_custom_msa:\n",
        "    text_file.write(f\"add_custom_msa={add_custom_msa} msa_format={msa_format}\\n\")\n",
        "  text_file.write(f\"homooligomer={I['homooligomer']}\\n\")\n",
        "\n",
        "  text_file.write(f\"pair_mode={pair_mode}\\n\")\n",
        "  if pair_mode != \"unpaired\":\n",
        "    text_file.write(f\"pair_cov={pair_cov}\\n\")\n",
        "    text_file.write(f\"pair_qid={pair_qid}\\n\")\n",
        "\n",
        "  if I[\"ori_sequence\"] != mod_I[\"ori_sequence\"]:\n",
        "    text_file.write(f\"mod_sequence={mod_I['ori_sequence']}\\n\")\n",
        "    text_file.write(f\"trim={trim}\\n\")\n",
        "    text_file.write(f\"trim_inverse={trim_inverse}\\n\")\n",
        "\n",
        "  if \"cov\" in dir():\n",
        "    text_file.write(f\"cov={cov}\\n\")\n",
        "    text_file.write(f\"qid={qid}\\n\")\n",
        "  else:\n",
        "    text_file.write(f\"cov=0\\nqid=0\\n\")\n",
        "\n",
        "  text_file.write(f\"max_msa={max_msa}\\n\")\n",
        "  text_file.write(f\"subsample_msa={subsample_msa}\\n\")\n",
        "  text_file.write(f\"num_relax={num_relax}\\n\")\n",
        "  text_file.write(f\"use_turbo={use_turbo}\\n\")\n",
        "  text_file.write(f\"use_ptm={use_ptm}\\n\")\n",
        "  text_file.write(f\"rank_by={rank_by}\\n\")\n",
        "  text_file.write(f\"num_models={num_models}\\n\")\n",
        "  text_file.write(f\"num_samples={num_samples}\\n\")\n",
        "  text_file.write(f\"num_ensemble={num_ensemble}\\n\")\n",
        "  text_file.write(f\"max_recycles={max_recycles}\\n\")\n",
        "  text_file.write(f\"is_training={is_training}\\n\")\n",
        "  text_file.write(f\"use_templates=False\\n\")\n",
        "  text_file.write(f\"-------------------------------------------------\\n\")\n",
        "\n",
        "  for n,key in enumerate(model_rank):\n",
        "    line = f\"rank_{n+1}_{key} pLDDT:{outs[key]['pLDDT']:.2f}\" + f\" pTMscore:{outs[key]['pTMscore']:.4f}\" if use_ptm else \"\"\n",
        "    text_file.write(line+\"\\n\")\n",
        "\n",
        "# --- Download the predictions ---\n",
        "os.system(f'zip -FSr {I[\"output_dir\"]}.zip {I[\"output_dir\"]}')\n",
        "if IN_COLAB:\n",
        "  files.download(f'{I[\"output_dir\"]}.zip')\n",
        "else:\n",
        "  print(\"this notebook appears to be running locally, to download click folder icon to the left, navigate to file, right click and download\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# License\n",
        "\n",
        "The source code of ColabFold is licensed under [MIT](https://raw.githubusercontent.com/sokrypton/ColabFold/main/LICENSE). Read more about the AlphaFold license [here](https://github.com/deepmind/alphafold)."
      ],
      "metadata": {
        "id": "0RoRCHFJZgmF"
      }
    }
  ]
}