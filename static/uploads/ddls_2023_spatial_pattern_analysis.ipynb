{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3ybMqV3o-E4"
      },
      "source": [
        "\n",
        "#**Spatial Pattern Analysis**\n",
        "\n",
        "## Computer lab notebook for [DDLS 2023 course](https://ddls.aicell.io/course/ddls-2023), module 3.\n",
        "\n",
        "In this notebook, we will cover Ripley’s K curve testing, DBSCAN and Voronoi Tessellation.\n",
        "\n",
        "Here are the references:\n",
        " - [Ripley K demo notebook](https://github.com/GeostatsGuy/PythonNumericalDemos/blob/master/Ripley_K_demo.ipynb)\n",
        " - [DBSCAN demo in scikit-learn](https://scikit-learn.org/stable/auto_examples/cluster/plot_dbscan.html)\n",
        " - [SR-Tesseler: a method to segment and quantify localization-based super-resolution microscopy data](https://www.nature.com/articles/nmeth.3579)\n",
        "\n",
        "\n",
        "## Prerequistes\n",
        "Before we start the computer lab, please use Google Search or consult ChatGPT to find answers to the following questions:\n",
        "\n",
        " - What is Ripley’s K curve and how is it useful in spatial point pattern analysis?\n",
        " - How does DBSCAN algorithm work and what distinguishes it from other clustering algorithms like K-means?\n",
        " - What is Voronoi tessellation? And how it can be used to analyse localization-based super-resolution microscopy data?\n",
        " - How do clustering algorithms like DBSCAN or spatial point patterns like Ripley’s K curve contribute to understanding cellular processes or diseases?\n",
        "\n",
        " You can also find the anwsers for many of these questions in the lecture slides and the references above.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-dzmKoNrwPQ"
      },
      "source": [
        "## Getting started\n",
        "\n",
        " * Click \"Connect\" in the top right corner (we won't need GPU this time, so the default runtime type will work)\n",
        " * Press `Ctrl + S` or use the `File` menu to save the current notebook to your google drive\n",
        "\n",
        "Now run the following cell to setup some libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JR-oiwttW3RY"
      },
      "outputs": [],
      "source": [
        "!pip install -U shareloc-utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8w2WTc0sH-U"
      },
      "source": [
        "### Download Super-resolution microscopy data from shareloc.xyz\n",
        "\n",
        "ShareLoc.XYZ is a website for sharing super-resolution microscopy data.\n",
        "\n",
        "Here we download an image of microtuble here: https://shareloc.xyz/#/r/7234160\n",
        "\n",
        "You can visualize the image [here](https://shareloc.xyz/shareloc-potree-viewer.html?pointShape=circle&pointSizeType=adaptive&unit=nm&name=cell-8/data.smlm&load=https://imjoy-s3.pasteur.fr/public/pointclouds/10.5281/zenodo.7234161/cell-8/data.potree.zip\n",
        ")."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tnauEUBZgcxb"
      },
      "outputs": [],
      "source": [
        "!wget https://zenodo.org/api/files/0d7b0d10-0503-416f-9a64-6fc553c041a4/cell-8/data.smlm -O cell-8.smlm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHizvFZ8wGjs"
      },
      "source": [
        "## Load the SMLM dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2t2a6eJwFoz"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "from scipy.spatial import distance_matrix\n",
        "from shareloc_utils.smlm_file import read_smlm_file, plot_histogram\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from shareloc_utils.smlm_file import read_smlm_file, plot_histogram\n",
        "\n",
        "def load_data(file_path, points=None):\n",
        "    # parse the .smlm file\n",
        "    manifest = read_smlm_file(file_path)\n",
        "    # one file can contain multiple localization tables\n",
        "    tables = manifest[\"files\"]\n",
        "    data = tables[0][\"data\"]\n",
        "    # Let's normalize the coordinates to [-1, 1]\n",
        "    x_real = data['x'] / data['x'].max() * 2 -1.0\n",
        "    y_real = data['y'] / data['y'].max() * 2 -1.0\n",
        "    if points:\n",
        "        x_real, y_real = x_real[0:points], y_real[0:points]\n",
        "\n",
        "    # Compute the squared distances from the origin for each point\n",
        "    squared_distances = x_real ** 2 + y_real ** 2\n",
        "\n",
        "    # Create a boolean mask for points that lie within the circle (squared distance <= 1)\n",
        "    inside_circle_filter = squared_distances <= 1\n",
        "\n",
        "    # Use the boolean mask to filter both x_real and y_real\n",
        "    x_real = x_real[inside_circle_filter]\n",
        "    y_real = y_real[inside_circle_filter]\n",
        "    return x_real, y_real\n",
        "\n",
        "\n",
        "# load real data with specified point number\n",
        "x_real, y_real = load_data(\"cell-8.smlm\", points=10000)\n",
        "\n",
        "# generate a histogram image for the data and display it\n",
        "histogram = plot_histogram({\"x\": x_real, \"y\": y_real}, pixel_size=0.01, value_range=(0, 10))\n",
        "plt.figure()\n",
        "plt.imshow(histogram)\n",
        "\n",
        "\n",
        "# print data size and range information\n",
        "print(len(x_real), len(y_real), x_real.min(), x_real.max(), y_real.min(), y_real.max())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pwtz7ezSvKDK"
      },
      "source": [
        "# Spatial Pattern Analysis: Ripley's K Curve\n",
        "This part of the notebook introduces you to Ripley's K function, a statistical test used in spatial pattern analysis. We'll start by generating random x, y coordinates to simulate Complete Spatial Randomness (CSR), then we'll apply Ripley's K curve to the real Single Molecule Localization Microscopy (SMLM) dataset you've just downloaded.\n",
        "\n",
        "\n",
        "For convinience, we will use [ripleyk.calculate_ripley](https://github.com/SamPIngram/RipleyK/tree/master) to compute the K values.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmOAZe8ivUZT"
      },
      "source": [
        "### Generate Random x, y Coordinates\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKuSXhEbsd7x"
      },
      "outputs": [],
      "source": [
        "# Number of points\n",
        "N = len(x_real)\n",
        "\n",
        "# Generate random x and y coordinates\n",
        "import random\n",
        "import numpy as np\n",
        "xs = []\n",
        "ys = []\n",
        "radius = 1\n",
        "random.seed(0)\n",
        "for i in range(0,N):\n",
        "    positioned = False\n",
        "    while positioned is False:\n",
        "        x = random.uniform(-radius, radius)\n",
        "        y = random.uniform(-radius, radius)\n",
        "        if (x**2)+(y**2) < radius**2:\n",
        "            xs.append(x)\n",
        "            ys.append(y)\n",
        "            positioned = True\n",
        "x_random = np.array(xs)\n",
        "y_random = np.array(ys)\n",
        "print(len(x_random), x_random.min(), y_random.max())\n",
        "\n",
        "\n",
        "# generate a histogram image for the random coordinates\n",
        "histogram = plot_histogram({\"x\": x_random, \"y\": y_random}, pixel_size=0.01, value_range=(0, 1))\n",
        "plt.imshow(histogram)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2yY9lZ6Oo5u"
      },
      "source": [
        "## Function to Compute Ripley's K Curve\n",
        "\n",
        "Let's create the Ripley's K function first.\n",
        "\n",
        "Note that this is just a very simple Ripley's K function implementation, feel free to change it to other variants."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYeE2U84La1l"
      },
      "outputs": [],
      "source": [
        "def ripleys_k_function(x, y, max_radius, area):\n",
        "    N = len(x)\n",
        "    distances = distance_matrix(np.column_stack((x, y)), np.column_stack((x, y)))\n",
        "    radii = np.linspace(0, max_radius, 20)\n",
        "    K_values = []\n",
        "\n",
        "    for r in radii:\n",
        "        neighbors = np.sum(distances < r)\n",
        "        K = neighbors / (N * N) * area\n",
        "        K_values.append(K)\n",
        "\n",
        "    return radii, K_values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97ov_laQO5rr"
      },
      "source": [
        "### Compute Ripley's K Curve for random points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTs7vhYnOxox"
      },
      "outputs": [],
      "source": [
        "radii, K_values_random = ripleys_k_function(x_random, y_random, 0.2, 1)\n",
        "\n",
        "plt.plot(radii, K_values_random)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vqa2m6n5PArW"
      },
      "source": [
        "\n",
        "## Exercise 1: Compute Ripley's K Curve for real data\n",
        "\n",
        "Now complete the following execises:\n",
        "\n",
        " - plot the Ripley's K Curve for the example SMLM image (`cell-8.smlm`)\n",
        " - compare the Ripley's K Curve with random points by plotting them in the same plot\n",
        "\n",
        "Here are some code which you may find useful:\n",
        "```python\n",
        "# load real data with specified point number\n",
        "x_real, y_real = load_data(\"cell-8.smlm\", points=10000)\n",
        "```\n",
        "\n",
        "To display the image\n",
        "```python\n",
        "# generate a histogram image for the data and display it\n",
        "histogram = plot_histogram({\"x\": x_real, \"y\": y_real}, pixel_size=0.01, value_range=(0, 10))\n",
        "plt.figure()\n",
        "plt.imshow(histogram)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_emwjSkO_kd"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jEiscFFQzr7"
      },
      "source": [
        "## Exercise 2: Changing point number\n",
        "\n",
        "Try to change the points number when loading the data, try `points=100`, `points=1000` and `points=10000`, display the histogram image first to get an intuition and plot the Ripley's K Curve, try to understand why."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbOyjO5EQyKI"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQG63LkSR7EV"
      },
      "source": [
        "## DBSCAN Clustering\n",
        "\n",
        "In this part of the tutorial, we'll explore how to use the DBSCAN clustering algorithm to analyze spatial data. Specifically, we'll apply DBSCAN on the real Single Molecule Localization Microscopy (SMLM) data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_j_I9b7sSONG"
      },
      "source": [
        "### Prepare Data for Clustering\n",
        "We'll combine the x and y coordinates into a single data matrix, which will be passed into the DBSCAN algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PusgC0-RaW-"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "x_real, y_real = load_data(\"cell-8.smlm\", points=10000)\n",
        "X = np.column_stack((x_real, y_real))\n",
        "\n",
        "print(X.shape, X.min(), X.max())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8sYXMhGSSSg"
      },
      "source": [
        "### Perform DBSCAN Clustering: First attempt\n",
        "\n",
        "Let's try DBSCAN and see if it can detect clusters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcxG791iSU1z"
      },
      "outputs": [],
      "source": [
        "# Define DBSCAN parameters\n",
        "eps = 0.1  # The radius of the neighborhood\n",
        "min_samples = 10  # The minimum number of samples in a neighborhood for a point to be considered as a core point\n",
        "\n",
        "# Apply DBSCAN\n",
        "dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
        "labels = dbscan.fit_predict(X)\n",
        "\n",
        "# Number of clusters\n",
        "n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
        "\n",
        "print(f'DBSCAN Clustering: {n_clusters} clusters found')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6biBT-LFUU8S"
      },
      "source": [
        "**As you may noticed, the detected cluster number is wrong, it's because we didn't set the right parameters. Namely the `eps` and `min_samples`**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HX93CPSkUExb"
      },
      "source": [
        "### Display the result\n",
        "\n",
        "Despite the incorrect detection, let's see what it found first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pg4VytoSXgR"
      },
      "outputs": [],
      "source": [
        "plt.scatter(x_real, y_real, c=labels, cmap='rainbow')\n",
        "plt.title(f'DBSCAN Clustering: {n_clusters} clusters found')\n",
        "plt.xlabel('X Coordinate')\n",
        "plt.ylabel('Y Coordinate')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6LT_hF1Taob"
      },
      "source": [
        "\n",
        "### Exercise 3: Fix the DBSCAN parameters\n",
        "\n",
        "In this exercise, use ChatGPT to help you find the correct parameters.\n",
        "\n",
        "Construct a prompt with enough context information, considering include the following:\n",
        "   - Set a role for ChatGPT (e.g. `Act as a data scientist`)\n",
        "   - Describe the setting (e.g. you are using Colab notebooks) and what are you trying to achieve\n",
        "   - Describe how you loaded the data, provide the script for loading your data:\n",
        "   ```\n",
        "   x_real, y_real = load_data(\"cell-8.smlm\", points=10000)\n",
        "   X = np.column_stack((x_real, y_real))\n",
        "   print(X.shape, X.min(), X.max())\n",
        "   ```\n",
        "   describe what was printed so it knows the data shape and value range.\n",
        "   - Describe what you have tried (copy the code and the output), what went wrong and what do you expect\n",
        "   - Express your intent, e.g. tell ChatGPT that you want some code which will automatically determine the DBSCAN parameters\n",
        "   - If the code provided ChatGPT produces error, copy and paste the error and ask it to fix it.\n",
        "\n",
        "Write down the prompt you used in a text block below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6Ku-3imYiAY"
      },
      "source": [
        "TODO: Your ChatGPT prompt:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJXS2Ys-TZ7K"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scuBr4VsdHQa"
      },
      "source": [
        "## Voronoi Tessellation\n",
        "In this section, we will explore the Voronoi tessellation method to perform clustering analysis. Voronoi tessellation can offer another way to understand spatial point patterns by partitioning a plane into regions based on distance to points in a specific subset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKZbXdksdTCC"
      },
      "source": [
        "### Perform Voronoi Tessellation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKqAcmjwYnxR"
      },
      "outputs": [],
      "source": [
        "from scipy.spatial import Voronoi, voronoi_plot_2d\n",
        "\n",
        "# Generate Voronoi tessellation\n",
        "vor = Voronoi(X)\n",
        "\n",
        "# Plot Voronoi tessellation\n",
        "fig, ax = plt.subplots()\n",
        "voronoi_plot_2d(vor, ax=ax)\n",
        "plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='rainbow')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfwLlE25dkT5"
      },
      "source": [
        "### Clustering with Voronoi Tessellation\n",
        "\n",
        "Now we can use Voronoi tessellation to detect clusters. For example, the area of each Voronoi cell can serve as a criterion to determine whether a point is part of a cluster or not.\n",
        "\n",
        "\n",
        "Let's see how does the area distribution looks like.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCXcGkFFcsJC"
      },
      "outputs": [],
      "source": [
        "from shapely.geometry import Polygon\n",
        "\n",
        "areas = []\n",
        "for region in vor.regions:\n",
        "    if not -1 in region and len(region) > 0:\n",
        "        polygon = Polygon([vor.vertices[i] for i in region])\n",
        "        areas.append(polygon.area)\n",
        "\n",
        "plt.hist(areas, bins=50)\n",
        "plt.title('Histogram of Voronoi Cell Areas')\n",
        "plt.xlabel('Area')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRfd8F02eAW-"
      },
      "source": [
        "One idea is to simply filter out regions by an area threshold (infered from the area distribution), and then we can use the filtered regions to detect clusters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47q1CSxdcwcN"
      },
      "outputs": [],
      "source": [
        "threshold = np.percentile(areas, 16)  # 10th percentile as the threshold\n",
        "\n",
        "# Identify clusters\n",
        "cluster_points = []\n",
        "for i, region in enumerate(vor.regions):\n",
        "    if not -1 in region and len(region) > 0:\n",
        "        polygon = Polygon([vor.vertices[j] for j in region])\n",
        "        if polygon.area < threshold:\n",
        "            cluster_points.append(vor.point_region[i])\n",
        "\n",
        "# Plot clusters\n",
        "plt.scatter(x_real, y_real, c='grey')\n",
        "plt.scatter(x_real[cluster_points], y_real[cluster_points], c='red')\n",
        "plt.title('Clusters Detected via Voronoi Tessellation')\n",
        "plt.xlabel('X Coordinate')\n",
        "plt.ylabel('Y Coordinate')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTgD5RTpeKoC"
      },
      "source": [
        "## Exercise 4: Improve Voronoi Tessellation Clustering Detection\n",
        "\n",
        "The above cluster detection attempt using area as the criterion is far from ideal, can you think of other criterion or other methods to detecting the clusters? Feel free to use ChatGPT to brainstorm ideas and guide it to implement the solution. How does it compare to DBSCAN? When designing the prompt, try to use the tips in Exercise 3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcsHE73pfEg_"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUujrId-zX5G"
      },
      "source": [
        "## Submitting your work\n",
        "\n",
        "After you have completed the exercises in the notebook:\n",
        " - During the lab session, tell the lab teacher so he/she can go through what you have done together and maybe ask you a few questions.\n",
        " - Export the notebook by using `File -> Download -> Download .ipynb`, then submit the notebook file to the [submission form](https://forms.gle/MpYYxyZqPeRF7f9r6).\n",
        "\n",
        "**Submission Deadline: Before Wednesday at 18:00**\n",
        "\n",
        "**NOTE: If you cannot join the lab session, please submit the notebook before the deadline, and find the lab teacher in a next lab session to go through what you have done together.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cDH7I2lziLV"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
